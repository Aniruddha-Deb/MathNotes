Mathematical Basics
================================

.. math:: \newcommand{\braket}[2]{\langle #1 | #2 \rangle}

The following section assumes the reader knows about the following mathematical
constructs:

1. Calculus, especially multivariable calculus
2. Linear algebra: basics of vector spaces, eigenvectors and eigenvalues
3. Real analysis: knowledge of sequences, subsequences and cauchy sequences

Hilbert Space
##################################################

Recapping from vector spaces, a vector space :math:`X` is called:

1. A *normed linear space* if for every :math:`f \in X` there is a real number 
   :math:`||f||`, called the *norm* of :math:`f`, such that 

   #. :math:`||f|| \ge 0`,
   #. :math:`||f|| = 0 \ \mathrm{iff} \ f = 0`,
   #. :math:`||cf|| = |c|||f||` for every scalar c, and
   #. :math:`||f + g|| \le ||f|| + ||g||` (Triangle Inequality)


2. An *inner product space* if for every :math:`f, g \in X` there exists a complex
   number :math:`\langle f, g \rangle` called the *inner product* of f and g, 
   such that

   #. :math:`\langle f, f \rangle` is real and greater than zero,
   #. :math:`\langle f, f \rangle = 0` if and only if :math:`f = 0`,
   #. :math:`\langle g, f \rangle = \langle f, g \rangle^*`,
   #. :math:`\langle af_1 + bf_2, g\rangle = a\langle f_1,g \rangle + b\langle f_2, g \rangle`

Note that every inner product space is a normed linear space, as each inner 
product determines a norm by the formula :math:`||f|| = \langle f, f \rangle ^{1/2}`.

As an example, consider the vector space :math:`\Bbb{R}^2`. This vector space 
has two basis vectors, :math:`\hat i` and :math:`\hat j`. The norm of any vector
:math:`\pmb{r_1} = a\hat i + b\hat j` is defined as :math:`\sqrt{a^2 + b^2}`, and the inner
product with another vector :math:`\pmb{r_2} = c\hat i + d\hat j` i.e. 
:math:`\langle \pmb{r_1}, \pmb{r_2} \rangle` is defined as the dot product, which
is :math:`ac + bd`.

Another important concept in vector spaces is that of *completeness*. If any 
convergent sequence is also a cauchy sequence in a vector space :math:`X`, then
:math:`X` is said to be *complete* 

We now come to the definition of Banach and Hilbert spaces: **A complete normed
linear space is called a Banach Space**, and **A Banach space whose norm is 
determined by an inner product is called a Hilber space**

If the above definitions went over your head, don't worry. All you need to know
about hilbert spaces is that they are vector spaces equipped with an inner product, 
and they are also complete, which allows us to use calculus techniques on 
functions defined here. Hilbert spaces are key to quantum mechanics as they 
support an infinite number of basis vectors, and also allow the definition of 
functions on the space, thereby acting as function spaces as well.

	In quantum mechanics, all wavefunctions reside in the hilbert space

Dirac (Bra-Ket) Notation
##################################################

Dirac notation is an effective way of representing states and operations in 
vector space. It consists of a *Bra* :math:`\bra{a}`, which is a map from 
:math:`V \to \Bbb{C}`, and a *Ket* :math:`\ket{b}`, which, as discussed previously
is just a vector. As a concrete example, consider 

.. math:: \ket{b} = \left( \begin{array}{c} b_1 \\ b_2 \\ . \\ . \\ . \\ b_n \end{array} \right)

and consider

.. math:: \bra{a} = \left( \begin{array}{c c c c c c} a_1 & a_2 & . & . & . & a_n \end{array} \right)

Then in dirac notation, we can define :math:`\braket{a}{b}` as 

.. math:: 

	\begin{align}
	\braket{a}{b} &= \left( \begin{array}{c c c c c c} a_1 & a_2 & . & . & . & a_n \end{array} \right) \cdot \left( \begin{array}{c} b_1 \\ b_2 \\ . \\ . \\ . \\ b_n \end{array} \right) \\
	&= a_1b_1 + a_2b_2 + ... + a_nb_n
	\end{align}

Note that every vector :math:`\ket{b}` has a corresponding dual bra :math:`\bra{b}`, 
which is defined as

.. math:: \bra{b} = \left( \begin{array}{c c c c c c} b_1^* & b_2^* & . & . & . & b_n^* \end{array} \right)

This is true, as by the definition of an inner product space :math:`\braket{b}{b} = ||b||^2`, and
:math:`\braket{b}{b} = ||b_1||^2 + ||b_2||^2 + ... + ||b_n||^2 = ||b||^2`.

This definition leads to some interesting formulae: for example,

.. math:: \braket{a}{b} = \braket{b}{a}^*

and also allows the working of operators, which are more like transformations

.. math:: \hat{T}\ket{b} = \left( \begin{array}{c c c c c} t_{11} & t_{12} & . & . & t_{1n} \\ t_{21} & t_{22} & . & . & t_{2n} \\ .&.&.& &. \\ .&.& &.&. \\ t_{n1} & t_{n2} &.&.&t_{nn} \end{array} \right) \cdot 
		  \left( \begin{array}{c} b_1 \\ b_2 \\ . \\ . \\ b_n \end{array} \right)

The question that arises now is **why don't we just use linear algebra constructs
in quantum mechanics instead of getting into Hilbert spaces?** The answer to 
that question arises when we use infinite dimensional vectors in quantum mechanics
(not something I'll cover in these notes), as well as once we start using 
functions rather than fixed states to express position (this we will do). Once 
this happens, hilbert spaces become a more appropriate tool to use rather than
matrices, which become clumsy. Since hilbert spaces also include vector spaces
with a finite number of basis vectors, we can use both matrices and hilbert space
constructs while dealing with problems of this sort. The two-state system 
discussed previously is mainly dealt with using matrices, as you would have found
out if you would have visited the Wikipedia page.

TODO some more stuff: eigenfunctions and eigenvalues revisited, expected values,
inner product for functions, orthogonality and sandwitching operators.
